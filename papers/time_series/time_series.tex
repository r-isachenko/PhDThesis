\documentclass[12pt,twoside, notitlepage]{article}
%\usepackage{jmlda}
%\usepackage{titling} %��� ���������� ���������� (���, ����)
%\usepackage{lineno} %��������� �����
\usepackage{cite} %������ �� ���������� � ���� [x-y]
\usepackage{abstract}
\usepackage[cp1251]{inputenc}
\usepackage{amsmath,amssymb,mathrsfs,mathtext}
\usepackage{a4wide}
\usepackage[english,russian]{babel}
\usepackage[T2A]{fontenc}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage{subfig}
\usepackage{url}
\usepackage[usenames]{color}
\usepackage{colortbl}
\usepackage{algorithm}
%\usepackage[noend]{algorithmic}
\usepackage[noend]{algcompatible}

\floatname{algorithm}{��������}
\definecolor{KwColor}{rgb}{0,0,0.6}
\newcommand{\vkKw}[1]{{\bf\color{KwColor} #1}}
\def\algorithmicrequire{\vkKw{����:}}
\def\algorithmicensure{\vkKw{�����:}}
\def\algorithmicif{\vkKw{����}}
\def\algorithmicthen{\vkKw{��}}
\def\algorithmicelse{\vkKw{�����}}
\def\algorithmicelsif{\vkKw{����� ����}}
\def\algorithmicfor{\vkKw{���}}
\def\algorithmicforall{\vkKw{��� ����}}
\def\algorithmicdo{}
\def\algorithmicand{\vkKw{�}}
\def\algorithmicwhile{\vkKw{����}}
\def\algorithmicrepeat{\vkKw{���������}}
\def\algorithmicuntil{\vkKw{����}}
\def\algorithmicloop{\vkKw{����}}
\def\algorithmiccomment#1{\quad// {\sl #1}}
\newcommand{\vkProcedure}[1]{\text{#1}\:}
\newcommand{\PROCEDURE}[1]{\medskip\STATEx\vkKw{���������} \vkProcedure{#1}}
\newcommand{\RR}{\mathbb{R}}
\bibliographystyle{gost780}
\renewcommand{\baselinestretch}{1.2}

\newcommand{\Section}[1]{
    \section*{#1}\addcontentsline{toc}{section}{#1}
}   %Section ��� ���������
\begin{document}
\title
    {����������� �������� � ������� ��������������� ������������� ��������� �����\thanks{������ ��������� ��� ���������� ��������� ���� (������ 13-07-01163).}}
\date{}
\maketitle
\begin{center}
    �.\,�.~��������\footnote{���������� ������-����������� ��������, isa-ro@yandex.ru},
    �.\,�.~�������\footnote{�������������� ����� ��. �. �. ����������� ��� �� ���, strijov@ccas.ru}
\end{center}
    \textbf{���������:} ������ ��������� ���������� ������ �������������� ������������� ��������� �����.
    ������������ ����������� ��������� ���� ������������ ���������� �������.
    ��������� ���������� ���������� � ������������ ��������� ����� �������������� � ������� ��������� ������������ ������������� �������.
    ��� ��������� �������� ������������� � ������ ������ ������������ ������ ������������ ��������.
    ����������� �������� ��������� �������������� ���������� ����� ���������� ������, ������� ��������� ���� �� ������ ������ � ������� ��������� ���� �� ������ �������.
    ���������� ����� ���������� ������ ���������� � ������� ������� ������������.
    ��������� ������������ �������� ������� � ����������� ����������� ������� ������������� � ������� ������������.
    ��� ������� �������� ������������ ��������� �������� �������������� ����������� �� ������������� � �������� ������ ��������� � ������������� ���������� ��������

\bigskip
\textbf{�������� �����}: ������������� ��������� �����; ������������; ����������� ��������; �������� LMNN
%\linenumbers
\section{��������}
�������� ������ ��������������� ������������� ��������� �����~\cite{popova2015multiclass, ignatov2015multiclass}.
��� ������� ���� ������ ����� ��������������: ����� ������� ��������~\cite{guler2007mccsvm, ubeyli2007mccsvm2}, ��������� ����~\cite{anand1995mccnn}, ����������� ������~\cite{kafai2012mccbn}.
� ������ ������ ��� ������������� ��������� ����� ������������ ���� ��������� �������~\cite{chaovalitwongse2007knn}.

��� ��������� �������� ������������� ������������ ������������ ������ ������������ ��������~\cite{bellet2013mlsurvey, yang2006mlsurvey2, wang2015mlsurvey3}.
����������� �������� ��������� �������������� ���������� ����� ���������� ������ � ������� ��������� �������������� ������������ ������������ ��������.
� ���������� �������������� ��������� ���� ������ ������ ����������� ����� ���� � ����� �� ��������� �������, � ��������� ����, ������������� ������ �������, ���������� ���� �� �����.
������ ������������ �������� ����������� ��� ������������ ��������� ������~\cite{mcfee2010mlranking}, ������������� ���~\cite{guillaumin2009mlface}, ������������� ���������� ����~\cite{weinberger2008mldigits}.
� ������ ������ � �������� ��������� ������������ �������� ��� ������ �������� LMNN (Large Margin Nearest Neighbor)~\cite{weinberger2005lmnn}.
������ �������� ������� �� ����� ������ $k$ ��������� �������.
�������� ��� ������� ������� ������������ ���������� �� $k$ ��������� �������, ������������� ���� �� ������, � �������� ������� �� ������ �������, �������� �� ���������� ������� ���������� �� $k$-�� ���������� ������.

�������� LMNN ��������� ���������� ����� ���������.
� ������� ��������� �������������� �������� �������� ������� � ����� ������������.
���� ����������� ������ ������������ ������ ����������� ��������� ������������, �� ���������� �������� �����������, �.~�. ����� ���������.

��� ���������� ���������� ����� ���������� ������ � ������ ������ ������������ �� ������������ ������������ ���������� �������.
������������ ������������ ������� ������������ ������������� ������� DTW (Dynamic Time Warping)~\cite{berndt1994dtw}.
������ ������ ������������ ��������� ������ �������� � ������� ������ ������������ ����������� ���������� DBA (DTW Barycenter Avaraging)~\cite{petitjean2011dba}.
�������������, ���������� �� ���� ��������� �������, ������������� � ��������� ��������� ���������.
��� ��������� ������������ ������������� ����������� ��������� ���� ���� �������������.

����� �������, ���������� ������ ������������� ������������ ����� ������������ ���������� ���������� ����������, ������������ ��������� ����� ������������ ���������� �������, ������������ ��������, �������������.

� ������ ������ �������������� ����������� ���������� �� ������������� ��������� �����, �������������� ������������� �������, � �������� ������ ��������� ������������� ���������� ��������.
���� ������������~--- ���������� ��� ���������� �������� �� ����� ������� �������������.
�������� ������ �������� ������ ������������ ��������� � �������� ������ ��� �������.

\section{���������� ������}
����� ������ $\mathbf{x}_i \in \mathbb{R}^n$~--- ��������� ���, ������������������ ��������� ��������� ����������� �������� � ��������� ������� �������.
����� $\mathbf{X}$~--- ��������� ���� ��������� ����� ������������� ����� $n$, $Y = \{1, \dots, K\}$~--- ��������� ����� �������.
����� ������ ������� $\mathfrak{D} = \{(\mathbf{x}_i, y_i)\}_{i=1}^\ell$~--- ��������� �������� � ���������� ������� ������� $y_i \in Y$.

��������� ��������� ������, �������, ���������� ������ �������������
\[
    a: \mathbf{X} \to Y.
\]
������ ������ ���������� � ���� ������������
\begin{equation}
\label{eq:classifiers}
a(\mathbf{x}) = b \circ \mathbf{f} \circ G(\mathbf{x}, \{\mathbf{c}_e\}_{e = 1} ^ K),
\end{equation}
 ��� $G$~--- ��������� ������������ ��������� ����� ������������ ���������� �������~$\{\mathbf{c}_e\}_{e = 1} ^ K$, $\mathbf{f}$~--- �������� ������������ ��������, $b$~--- �������� �������������� �������������.

\paragraph{������������ ��������� �����.}

��� ��������� �������� � ������������ ��������� ������������� ������������ �������� ������������ ��������� ����� ������� ������ ������������ ���������.

����� $\mathbf{X}_e$ --- ��������� �������� ��������� ������� $\mathfrak{D}$, ������������� ������ ������ $e \in \{1, \dots, K\}$.
���������� ��������� �������� $\mathbf{X}_e = \{\mathbf{x}_i|y_i=e\}_{i=1}^\ell$ �� ���������� $\rho$ ������� ������ $\mathbf{c}_e \in \mathbb{R}^n$ �����, ���
\begin{equation}
\label{centroid_task}
    \mathbf{c}_e = \mathop{\text{argmin}}\limits_{{\mathbf{c} \in \mathbb{R}^n}}\sum_{\mathbf{x}_i \in \mathbf{X}_e}
    {\rho(\mathbf{x}_i ,\mathbf{c})}.
\end{equation}

��� ���������� ��������� ������������ � �������� ���������� ����� ���������� ������ ������������ ���� ���������� ���������~\cite{goncharov2015cost}, ��������� ������� ������������ ������������� �������.
��������� ������� ��������������� ������~(\ref{centroid_task}) �������� � ���������~\ref{DBA_pseudo}.

\begin{algorithm}[h]
\caption{���������� ��������� $\text{DBA}(\mathbf{X}_e, \text{n\_iter})$}
\label{DBA_pseudo}
\begin{algorithmic}[1]
\REQUIRE $\mathbf{X}_e$~--- ��������� ��������� �����, ������������� ������ � ���� �� ������, n\_iter~--- ���������� �������� ���������.
\ENSURE $\mathbf{c}$~--- �������� ��������� $\mathbf{X}_e$.

\STATE {������ ��������� ����������� ����������� ��������� $\mathbf{c}$;}
\FOR {$i = 1, \dots, \text{n\_iter}$}
    \FOR {$\mathbf{x} \in \mathbf{X}_e$}
        \STATE{��������� ������������� ���� ����� $\mathbf{c}$ � $\mathbf{x}$}
        \STATEx $ \quad \quad \text{alignment}(\mathbf{x}) := \text{DTWalignment}(\mathbf{c}, \mathbf{x})$;
    \ENDFOR
    \STATE {���������� ����������� ��������� �������� ��� ������� ������� �������}
    \STATEx {$ \quad \text{alignment} := \bigcup_{\mathbf{x} \in \mathbf{X}_e} \text{alignment}(\mathbf{x})$};
    \STATE {$\mathbf{c} = \text{mean}(\text{alignment})$}
\ENDFOR
\end{algorithmic}

\begin{algorithmic}[1]
\PROCEDURE {$\text{DTWalignment}(\mathbf{c}, \mathbf{x})$}
\REQUIRE $\mathbf{c}, \mathbf{x}$~--- ��������� ����.
\ENSURE alignment~--- ������������� ����.\COMMENT {������ ������ ���������� ����~$\mathbf{x}$ ��������� � ����������� ������������ ������� ���������� ����~$\mathbf{c}$}

\STATE {��������� $n \times n$-������� ���������� DTW}
\STATEx {$\text{cost} := \text{DTW}(\mathbf{c}, \mathbf{x})$};

\STATE {��������� ������������� ���� �� ������� ����������}
\STATEx {$\text{alignment} := \text{DTWpath}(\text{cost})$};
\end{algorithmic}
\end{algorithm}
\newpage
����� ��������� ������������ ����� ��������� ���:
\begin{itemize}
    \item[1)]
    ��������� ��������� ���������� ������� $\{\mathbf{c}_e\}_{e = 1}^K$;
    \item[2)]
    �� ��������� ���������� ����� ���� ���������� ��������� ����� ������
    ��������� ����� $\mathbf{x}_i$ � ���������� ��� ������ $\mathbf{c}_{y_i}$;
    \item[3)]
    �� ������� ���� ������������ ����������� ��������� ���;
    \item[4)]
    �������� ��������� ����������� ��������� ����� � �������� �������� � ����������� �� ���������.
\end{itemize}

����������� ������������ ������ ����� ��������� ����������� ��������� �����.

\paragraph{����������� ��������.}

������ �� ��������� ����������� ��������� ����� ���������� ������������
\[
    d_\mathbf{A} (\mathbf{x}_i, \mathbf{x}_j) = \sqrt{(\mathbf{x}_i - \mathbf{x}_j)^\mathsf{T} \mathbf{A} (\mathbf{x}_i - \mathbf{x}_j)},
\]
��� ������� ������������� $\mathbf{A} \in \RR^{n \times n}$ �������� ������������ � �������������� ������������ ($\mathbf{A}^\mathsf{T} = \mathbf{A}$, $\mathbf{A} \succeq 0$).
���������� ������� $\mathbf{A}$ � ���� ���������� $\mathbf{A} = \mathbf{L}^\mathsf{T}  \mathbf{L}$.
������� $\mathbf{L} \in \RR^{p \times n}$~--- ������� ��������� ��������������, ��� $p$ ������ ����������� ���������������� ������������. ���� �������� $p < n$, �� ���������� �������� ����������� ������������ ������������.

���������� $d_\mathbf{A} (\mathbf{x}_i, \mathbf{x}_j)$ ���� ��������� ���������� ����� $\mathbf{Lx}_i$ � $\mathbf{Lx}_j$:
\[
    d_\mathbf{A} (\mathbf{x}_i, \mathbf{x}_j) = \sqrt{(\mathbf{x}_i - \mathbf{x}_j)^\mathsf{T} \mathbf{L}^\mathsf{T} \mathbf{L} (\mathbf{x}_i - \mathbf{x}_j)} = \sqrt{(\mathbf{L} (\mathbf{x}_i - \mathbf{x}_j))^\mathsf{T} (\mathbf{L} (\mathbf{x}_i - \mathbf{x}_j))} = \|\mathbf{L} (\mathbf{x}_i - \mathbf{x}_j)\|_2.
\]

� �������� ��������� ������������ �������� � ������ ������ ��� ������ �������� LMNN. ������ �������� �������� � ���� ���� ������ $k$ ��������� �������. ������ ���� ����������� � ����������� ���������� ����� $k$ ���������� ���������, ������������ � ����� ������. ������� ���������� �������� � ����
\[
    Q_1(\mathbf{L}) = \sum_{j \rightsquigarrow i} \|\mathbf{L}(\mathbf{x}_i - \mathbf{x}_j)\|^2 \rightarrow \min_{\mathbf{L}},
\]
��� $j \rightsquigarrow i$ ��������, ��� $\mathbf{x}_j$ �������� ����� �� $k$ ��������� ������� ��� $\mathbf{x}_i$.
������ ���� ������� � ������������ ���������� ����� ������ �������� � ��� ���������-������������. ��������-����������� ��� $\mathbf{x}_i$ ������� ������ $\mathbf{x}_l$ �����, ���
\begin{equation}
\label{impostor}
    \|\mathbf{L}(\mathbf{x}_i - \mathbf{x}_l)\|^2 \leq \|\mathbf{L}(\mathbf{x}_i - \mathbf{x}_j)\|^2 + 1, \quad \text{��� $j \rightsquigarrow i$}.
\end{equation}
����� �������, ���������� �������������� ��������� ����������:
\[
    Q_2(\mathbf{L}) = \sum_{j \rightsquigarrow i} \sum_l(1 - y_{il})\bigl[1 + \|\mathbf{L}(\mathbf{x}_i - \mathbf{x}_j)\|^2 - \|\mathbf{L}(\mathbf{x}_i - \mathbf{x}_l)\|^2\bigr]_+ \rightarrow \min_{\mathbf{L}},
\]
��� $y_{il} = 1$, ���� $y_i = y_l$, � $y_{il} = 0$ � ��������� ������.
������������� ������ ��������� ���������� ������ �� �������, ������� ������������� �������~(\ref{impostor}).

������ ������������ �������� ������� � ���������� ��������� �������������� $\mathbf{f}(\mathbf{x}) = \mathbf{Lx}$, �� ���� ���������� ������� $\mathbf{L}$ � ���� ������� ��������������� ������
\begin{equation}
\label{Qmin}
    Q(\mathbf{L}) = \mu Q_1(\mathbf{L}) + (1 - \mu) Q_2(\mathbf{L}) \rightarrow \min_{\mathbf{L}},
\end{equation}
��� $\mu \in (0, 1)$~--- ������� ��������, ������������ ����� ������� �� ������������.
������~(\ref{Qmin}) ������������ ����� ������ ����������������� ����������������~\cite{vandenberghe1996semidefinite} � ����� ���� ������ ������������� ���������������� ��������.

\paragraph{������������� ��������� �����.}

����� $\mathbf{x} \in \mathbf{X}$~--- ������������� ��������� ���. ����������� ��������� ��� $\mathbf{x}$ ������������ ���� ���������� �������
\[
    \mathbf{\hat{x}}_e = G(\mathbf{x}, \mathbf{c}_e), \quad \text{���} \quad e = \{1, \dots, K\}.
\]
������� ��������� ��� � ������, ��� �������� ���������� ���������� �� ���������������� ���������. � �������� ���������� ���������� ��������� ������� ������������ � ������������� �������� $\mathbf{A}$
\[
    \hat{y} = \mathop{\text{argmin}}\limits_{e \in \{1, \dots, K\}}d_\mathbf{A}(\mathbf{\hat{x}}_e, \mathbf{c}_e).
\]
����� ���������� ����������� ���������� ������� � ���������� ����������� ������� ������������� ��������� ������������� ����������� � ��������� ���������� ����� ���������� ����������� � ������ �������������� ���������.

��� ������ �������� ������ ��������� ����� ��������� ������ ������������� ��� ���� ����������� ������������������ �������� �������� ������� $\mathfrak{U}$:
\[
    \text{error} = \frac1{|\mathfrak{U}|} \sum_{i = 1} ^ {|\mathfrak{U}|} [a(\mathbf{x}_i) \ne y_i].
\]

\section{�������������� �����������}
���� ��������������� ������������~--- ��������� ����������������� ������������� �������.
��������������, ��� ����������� �������� ��������������� ������������� �������� ���������� ��� ���������� �������� �� ����� ������� ������������� ���������� ��������.

��� ���������� �������� ��������������� ������������ ���� ������������ ������������� ��������� ����, ������������� ���� �������~\cite{Isachenko2015code}.
������ �����~--- ������ ���� $sin(x + b)$, ��� �������� $b$ ���������� ����� ������� ���������� ����.
������ �����~--- ������������ ������� � ���������� �������� �� ��������� �����.
�� ������ ��������� ��� ��� ������� ���������� ���.
����� ��������� ����� ������� ������ = 60.
����� ������� ���������� ���� $n = 50$.

����������� ��������� ������� ����������������� �� ���.~\ref{centroids_synthetic}.
�� ������� �����, ��� ��������� ��������� ���������� ������ ��������� �����.
\begin{figure}[h]
\centering
    \includegraphics[width=0.45\linewidth]{fig/centroids_synthetic_noize}
    \caption{��������� ������������� ��������� �����}
\label{centroids_synthetic}
\end{figure}

��� ���� ����� ��������� � ���������������� ���������� ������������ ��������, ������
��������� ���� ������������������ � ������������ � ���������� �������� � � ������������ � �������� ������������.
����� ��������� ������� $k = 5$, ����������� ���������������� ������������ $p = 40$.
���������� ������ ������������� ���������:

��������� ������� --- $27\%$

������� ������������ --- $6\%$.

�������� ������~\cite{UCI_HarDataset} ������������ ����� ��������� ���� ������������� ���������� ��������.
������ �� ����� ������� �������������� ������������ ���������� ���������� ����������.
��� ���������� ��������������� ������������ ���� ������� �� $200$ �������� ������� ������.
����� ������� ���������� ���� ��������� $n = 128$ �������� �������.

����������� ��������� ������� ���������� �� ���.~\ref{centroids_real}.
��������� ��������� �������� ��������������, ������������ ��������� ����� ��������� ���������� ��������.
\begin{figure}[h]
\centering
    \includegraphics[width=1\linewidth]{fig/centroids_200_2}
    \caption{��������� ��������� ����� �������������}
\label{centroids_real}
\end{figure}
�� ���.~\ref{raw_ts} �������� ������� ��������� ����� ������� ������. ��� �� ��������� ���� ����� ��������� ������������ ������������ ����������� ���������� ���������� �� ���.~\ref{aligned_ts}.
\begin{figure}[!h]
\centering
    \includegraphics[width=1\linewidth]{fig/raw_ts}
    \caption{��������� ���� �������������}
\label{raw_ts}
\end{figure}
\begin{figure}[!h]
\centering
    \includegraphics[width=1\linewidth]{fig/aligned_ts}
    \caption{����������� ��������� ���� �������������}
\label{aligned_ts}
\end{figure}

������ ������������� ��� ������������� ������������ �������� ���������~$37,5\%$.
�������� LMNN ��������� ��������� ���������: ����� ��������� �������~$k$,
����������� ���������������� ��������� ������������~$p$.
��� ������ ����������� ���������� ������������� ���������� �����-��������.
�� ���.~\ref{heat_map} ������ �������� ������ ������������� ��������� � ����������� �� ��� ����������.
�� ������ ������� �������� LMNN ����������� ����� ������������ � ����� ��������� �������,
� ��� ���������� ����������� ������������ �������� ������ ������������� ������.
\begin{figure}[h]
\centering
    \includegraphics[width=1\linewidth]{fig/heat_map}
    \caption{������ ������������� � ����������� �� ����������}
\label{heat_map}
\end{figure}

�������� �������� LMNN �� ���������� �����������: ����� ��������� ������� $k = 30$, �����������
��������� ������������ $p = 128$.
������ ������������� ���������~$17,25\%$, ��� ����� ������ ������ ������������� � �������������� ���������� �������.

\begin{table}[!ht]
  \centering
  \caption{������� ��������������}
  \subfloat[][��������� �������]{\begin{tabular}{|l|l|l|l|l|l|l|}
    \hline
    \multirow{2}{*}{} & \multicolumn{6}{c|}{�������� ����� �������} \\ \cline{2-7}
                  & 1     & 2     & 3     & 4     & 5    & 6    \\ \hline
1                 & 80    & 0     & 5     & 0     & 0    & 0    \\ \hline
2                 & 4     & 56    & 33    & 0     & 0    & 0    \\ \hline
3                 & 5     & 5     & 86    & 0     & 0    & 0    \\ \hline
4                 & 7     & 8     & 5     & 168   & 4    & 21   \\ \hline
5                 & 51    & 61    & 57    & 12    & 192  & 11   \\ \hline
6                 & 53    & 70    & 14    & 20    & 2    & 168  \\ \hline
    \end{tabular}}
  \qquad
  \subfloat[][������� ������������]{\begin{tabular}{|l|l|l|l|l|l|l|}
    \hline
    \multirow{2}{*}{} & \multicolumn{6}{c|}{�������� ����� �������} \\ \cline{2-7}
                  & 1     & 2     & 3     & 4     & 5    & 6    \\ \hline
1                 & 151   & 12    & 13    & 0     & 0    & 0    \\ \hline
2                 & 10    & 142   & 14    & 0     & 0    & 0    \\ \hline
3                 & 9     & 10    & 171   & 0     & 0    & 0    \\ \hline
4                 & 10    & 7     & 0     & 173   & 9    & 21   \\ \hline
5                 & 2     & 11    & 0     & 12    & 186  & 9    \\ \hline
6                 & 18    & 18    & 2     & 15    & 5    & 170  \\ \hline
\end{tabular}}
\label{confussion_matrix}
\end{table}

� ����.~\ref{confussion_matrix} ������������ ������� �������������� ����������� ������������� ��� �������������
���������� ������� � ������� ������������.
������� ������������� �������� ������ ������� ��������, ������~--- ������������� ������.
������������ ������������ ������� �������������� ��������� �� ������� ���������������� ����������� ���������.

� ����.~\ref{improvement} ������������������ ���������� �������� ������������� ��� ������������� � �������� ���� ���������� ������� ������������.
����������� $i$-�� ������� � $j$-� ������ �������� ��������� ���� �������� ������ $i$, ���������� � ������ $j$. ������������� ��������� �������� ������������ ��������� ������� ������������� ���������� �������� �������������. ������������ ��������� ������������ ���������� ��� ������������� ������ ���� �������.
������ ������ ������������� ��������� ����� ���������� ����������: ������, ������ �����, ������ ����.

\begin{table}[!h]
\centering
\caption{���������� �������� ������������� ��� ������������� ���������� ������ ������� �������������}
\label{improvement}
\begin{tabular}{|l|l|l|l|l|l|l|}
\hline
\multirow{2}{*}{} & \multicolumn{6}{c|}{�������� ����� �������}       \\ \cline{2-7}
    & 1      & 2      & 3      & 4      & 5     & 6     \\ \hline
1   & \textbf{0,355}  & 0,06   & 0,04   & 0      & 0     & 0     \\ \hline
2   & 0,03   & \textbf{0,43}   & --0,095 & 0      & 0     & 0     \\ \hline
3   & 0,02   & 0,025  & \textbf{0,425}  & 0      & 0     & 0     \\ \hline
4   & 0,015  & --0,005 & --0,025 & \textbf{0,025}  & 0,025 & 0     \\ \hline
5   & --0,245 & --0,25  & --0,28  & 0      & \textbf{--0,03} & --0,01 \\ \hline
6   & --0,175 & --0,26  & --0,06  & --0,025 & 0,005 & \textbf{--0,01} \\ \hline
\end{tabular}
\end{table}

\section{����������}
� ������ ������ ��������� ����� ������ � ������� ������ �������������� ������������� ��������� �����.
������������ ���������� ������������� ��������� ��������� �����, ���������� �� ��������� ����������
� ������� ���������� ������� � ��������� ������� ������������.
�������� �������������� ����������� �� �������� ������ ��������� ������������� ���������� ��������.
����������� ������ ������������� �������� ������� �������� ������������� ���������� �������� �� �����
������� �������������.
\newpage
%\bibliography{lib}
%\renewcommand{\refname}{\section{����������}}
\begin{thebibliography}{10}

\bibitem{popova2015multiclass}
\emph{������~�.~�., �������~�.~�.}
\newblock ����� ����������� ������ ������������� ���������� ���������� ��
���������� ������������� // ����������� � �� ����������,
2015. �.~9. ���.~1. �.~79--89.

\bibitem{ignatov2015multiclass}
\emph{Ignatov~A.~D., Strijov~V.~V.}
\newblock Human activity recognition using quasiperiodic time series collected
  from a single tri-axial accelerometer // Multimedia Tools and Applications, 2015. P.~1--14.

\bibitem{guler2007mccsvm}
\emph{G{\"u}ler~I., {\"U}beyli~E.~D.}
\newblock Multiclass support vector machines for eeg-signals classification //
IEEE Transactions on Information Technology in Biomedicine, 2007. Vol.~11. No.~2. P.~117--126.

\bibitem{ubeyli2007mccsvm2}
\emph{{\"U}beyli~E.~D.}
\newblock Ecg beats classification using multiclass support vector machines
  with error correcting output codes // Digital Signal Processing, 2007. Vol.~17. No.~3. P.~675--684.

\bibitem{anand1995mccnn}
\emph{Anand~R., Mehrotra~K., Mohan~C.~K., Ranka~S.}
\newblock Efficient classification for multiclass problems using modular neural
  networks // IEEE Transactions on Neural Networks, 1995. Vol.~6. No.~1 P.~117--124.

\bibitem{kafai2012mccbn}
\emph{Kafai~M., Bhanu~B.}
\newblock Dynamic bayesian networks for vehicle classification in video // IEEE Transactions on Industrial Informatics,
2012. Vol.~8. No.~1. P.~100--109.

\bibitem{chaovalitwongse2007knn}
\emph{Chaovalitwongse~W.~A., Fan~Y.-J., Sachdeo~R.~C.}
\newblock On the time series k-nearest neighbor classification of abnormal
  brain activity // IEEE Transactions on Systems, Man and Cybernetics. Part A: Systems and Humans,
2007. Vol.~37. No.~6. P.~1005--1016.

\bibitem{bellet2013mlsurvey}
\emph{Bellet~A., Habrard~A., Sebban~M.}
\newblock A survey on metric learning for feature vectors and structured data //
arXiv preprint arXiv:1306.6709, 2013.

\bibitem{yang2006mlsurvey2}
\emph{Yang~L., Jin~R.}
\newblock Distance metric learning: A comprehensive survey. -- Michigan State University, 2006. Vol.~2.

\bibitem{wang2015mlsurvey3}
\emph{Wang~F., Sun~J.}
\newblock Survey on distance metric learning and dimensionality reduction in data mining //
Data Mining and Knowledge Discovery, 2015. Vol.~29. No.~2. P.~534--564.

\bibitem{mcfee2010mlranking}
\emph{McFee~B., Lanckriet~G.~R.}
\newblock Metric learning to rank // Proceedings of the 27th International Conference on Machine
  Learning (ICML-10), 2010. P.~775--782.

\bibitem{guillaumin2009mlface}
\emph{Guillaumin~M., Verbeek~J., Schmid~C.}
\newblock Is that you? Metric learning approaches for face identification // Proceedings of the IEEE 12th International Conference on Computer Vision. -- IEEE, 2009. P.~498--505.

\bibitem{weinberger2008mldigits}
\emph{Weinberger~K.~Q., Saul~L.~K.}
\newblock Fast solvers and efficient implementations for distance metric
  learning // Proceedings of the 25th International Conference on Machine
Learning, 2008. P.~1160--1167.

\bibitem{weinberger2005lmnn}
\emph{Weinberger~K.~Q., Blitzer~J., Saul~L.~K.}
\newblock Distance metric learning for large margin nearest neighbor
  classification // Advances in Neural Information Processing Systems 18 (NIPS 2005). -- Cambridge, MA: MIT Press, 2006. P.~1473--1480.

\bibitem{berndt1994dtw}
\emph{Berndt~D.~J., Clifford~J.}
\newblock Using dynamic time warping to find patterns in time series // KDD Workshop, 1994. Vol.~10. P.~359--370.

\bibitem{petitjean2011dba}
\emph{Petitjean~F., Ketterlin~A., Gan{\c{c}}arski~P.}
\newblock A global averaging method for dynamic time warping, with applications
  to clustering // Pattern Recognition, 2011. Vol.~44. No.~3. P.~678--693.

\bibitem{goncharov2015cost}
\emph{��������~�.~�., ������~�.~�., �������~�.~�.}
\newblock ����������� ������������� ��������� ����� � �������������
  ������������ ���������� ������� // ������� � �������� �����������, 2015. �.~25. �~4. �.~52--64.

\bibitem{vandenberghe1996semidefinite}
\emph{Vandenberghe~L., Boyd~S.}
\newblock Semidefinite programming // SIAM Review, 1996. Vol.~38. No.1. P.~49--95.

\bibitem{Isachenko2015code}
\emph{��������~�.~�.}
\newblock ���������� ��������� ������������� ��������� �����~// Sourceforge.net, 2015.
\newblock \url{http://sourceforge.net/p/mlalgorithms/code/HEAD/tree/Group274/Isachenko2015TimeSeries/code}.


\bibitem{UCI_HarDataset}
UCI repository. Human Activity Recognition Using Smartphones Dataset.
\newblock \url{https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones}.

\end{thebibliography}

\end{document}
