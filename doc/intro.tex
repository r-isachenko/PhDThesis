\addcontentsline{toc}{section}{Введение}
\chapter*{Введение}

Диссертационная работа посвящена построению математических моделей машинного обучения в пространствах высокой размерности.
Разработанные методы позволяют учесть зависимости, имеющиеся в исходных данных, с целью построения простой и устойчивой модели.


\textbf{Актуальность темы.} 

В работе исследуется задача декодирования сигналов. 
При построении моделей машинного обучения возникает необходимость построения низкоразмерного признакового пространства. 
Требуется по входному исходному сигналу предсказать отклик на этот сигнал.

Сложностью задачи является избыточность исходного описания данных. 
Исходное признаковое пространство является мультикоррелированным.
Финальная предсказательная модель оказывается неустойчивой.
Для построения простой, устойчивой модели применяются методы снижения размерности пространства~\cite{chun2010sparse,mehmood2012review}  и выбора признаков~\cite{katrutsa2015stress,li2017feature}.

В работе рассматриваются задачи с векторной целевой переменной. 
При предсказании векторной целевой переменной возникает необходимости в анализе структуры целевого пространства.
Целевое пространство содержит зависимости.
В работе предлагаются методы, которые позволяют учесть зависимости как в исходном пространстве объектов, так и в пространстве целевой переменной.

Методы снижения размерности пространства позволяют снизить размерность исходного пространства объектов, сложность модели существенно снижается. 
Алгоритмы снижения размерности позволяют найти оптимальные комбинации исходных признаков. 
В случае если количество таких комбинаций существенно меньше, чем число исходных признаков, то полученное представление снижает размерность.
Цель снижения размерности найти наиболее репрезентативные и информативные комбинации признаков для решения целевой задачи.

Выбор признаков является частным случаем снижения размерности пространства. 
Найденные комбинации признаков являются лишь подмножеством исходных признаков.
Таким образом появляется возможность отсеить шумовые неинформативные признаки.
Процедура выбора признаков может как зависеть, так и не зависеть от модели предсказания.

После нахождения оптимального представления данных с помощью снижения размерности, возникает задача нахождения правильной метрики в скрытом пространстве объектов.
В случае евклидова пространства естественным выбором метрики оказывается квадратичная норма.
Задача метрического обучения найти оптимальную метрику, связывающая объекты.

\vspace{0.5cm}
\textbf{Цели работы.}
\begin{enumerate}
	\item Исследовать задачу декодирования сигналов с многомерной целевой переменной.
	\item Предложить способ снижения размерности пространства, учитывающий зависимости в исходном пространстве сигналов, а также в целевом пространстве.
	\item Предложить процедуру выбора признаков для задачи декодирования сигналов.
	\item Исследовать линейные и нелинейные модели для решения поставленной модели, получить теоретические оценки оптимальности моделей.
	\item Провести вычислительный эксперимент для проверки адекватности предложенных методов.
\end{enumerate}


\vspace{0.5cm}
\textbf{Основные положения, выносимые на защиту.}
\begin{enumerate}
	\item Метод снижения размерности пространства, отображающий независимую и целевую переменные в единое скрытое низкоразмерное представление.
	\item Методы выбора признаков для задач с многомерной целевой переменной, учитывающие структуры пространств.
	\item Алгоритм выбора наиболее влиятельных параметров для оптимизации нелинейной модели.
	\item Алгоритм метрического обучения для временных рядов с процедурой их выравнивания.
	\item Программный комплекс, включающий прогностические модели для высокоразмерных данных. Проведены вычислительные эксперименты, подтверждающие адекватность методов.
\end{enumerate}

\vspace{0.5cm}
\textbf{Методы исследования.}
Для достижения поставленных целей используются линейные и нелинейные алгоритмы регрессии.
Для анализа временных рядов используются классические авторегрессионные методы.
Для извлечения признаков используются частотные характеристики временного ряда.
Для построения скрытого пространства используются линейные методы снижения размерности пространства, их нелинейные модификации, а также нейросетевые методы.
Для выбора признаков наряду с классическими методами, используются методы, основанные на решении задачи квадратичного программирования.
Для построения метрического пространства используются методы условной выпуклой оптимизации.

\vspace{0.5cm}
\textbf{Научная новизна.}

\vspace{0.5cm}
\textbf{Теоретическая значимость.}

\vspace{0.5cm}
\textbf{Практическая значимость.}

\vspace{0.5cm}
\textbf{Степень достоверности и апробация работы.}
Достоверность результатов потверждена математическими доказательствами, экспериментальной проверкой результатов предалаемых алгоритмов на реальных данных, публикациями результатов в рецензируемых научных изданиях, в том числе рекомендованных ВАК. 
Результаты работы докладывались и обсуждались на следующих научных конференциях.
\begin{enumerate}
	\item Международная научная конференция <<Ломоносов>>, 2016,~\cite{isachenko2016lomonosov}.
	\item Международная научная конференция  <<11th International Conference on Intelligent Data Processing: Theory and Applications>>, 2016,~\cite{Neychev2016IDP}.
	\item Всероссийская научная конференция <<Математические методы распознавания образов>>, 2017,~\cite{isachenko2017localmmro}.
	\item Международная научная конференция  <<12th International Conference on Intelligent Data Processing: Theory and Applications>>, 2018,~\cite{Isachenko2018plsidp}.
	\item Международная научная конференция  <<13th International Conference on Intelligent Data Processing: Theory and Applications>>, 2020, {\color{red} ???}.
\end{enumerate} 

Работа поддержана грантами Российского фонда фундаментальных исследований.
\begin{enumerate}
	\item {\color{red} ???}
\end{enumerate}

\vspace{0.5cm}
\textbf{Публикации по теме диссертации.}

Основные результаты по теме диссертации изложены в  {\color{red} ???} печатных изданиях, {\color{red} ???} из которых изданы в журналах, рекомендованных ВАК.

\begin{enumerate}
	\item Исаченко Р. В., Катруца А. М. Метрическое обучение и снижение размерности пространства в задачах кластеризации // Машинное обучение и анализ данных, 2016. T. 2. № 1. С. 17--25~\cite{isachenko2016metricjmlda}.
	\item Исаченко Р. В., Стрижов В. В. Метрическое обучение в задачах мультиклассовой классификации временных рядов // Информатика и её применения, 2016. Т. 10. № 2. С. 48--57~\cite{isachenko2016metricia}.
	\item Isachenko R. et al. Feature Generation for Physical Activity Classification // Artificial Intelligence and Decision Making, 2018. № 3. С. 20--27~\cite{isachenko2018feature}.
	\item Isachenko R. V., Strijov V. V. Quadratic programming optimization with feature selection for nonlinear models // Lobachevskii Journal of Mathematics, 2018. Т. 39. № 9. С. 1179--1187~\cite{isachenko2018quadratic}.
	\item Isachenko R. V., Vladimirova M. R., Strijov V. V. Dimensionality Reduction for Time Series Decoding and Forecasting Problems //DEStech Transactions on Computer Science and Engineering, 2018. №. optim.~\cite{isachenko2018plsdestech}.
\end{enumerate}

\vspace{0.5cm}
\textbf{Структура и объем работы.}

\vspace{0.5cm}
\textbf{Личный вклад.}
Все приведенные результаты, кроме отдельно оговоренных случаев, получены диссертантом лично при научном руководстве д.ф.-м.н. В. В. Стрижова.

\vspace{0.5cm}
\textbf{Краткое содержание работы по главам.}